# -*- coding: utf-8 -*-
"""naive_bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1muvkSUERRNktVP69ebBHgM10sK7SgkaX
"""

#Importing data and preprocessing
from pyspark.sql.functions import lower, regexp_replace, udf
from pyspark.ml.feature import Tokenizer, StopWordsRemover
from pyspark.sql.types import ArrayType, StringType
data = spark.read.option("header","true").option("escape", '"').csv('/FileStore/tables/IMDB_Dataset.csv')
data = data.select(regexp_replace('review', "[^a-zA-Z\\s]", " ").alias('review'), "sentiment")
data = data.select(regexp_replace('review', "\s+", " ").alias('review'), "sentiment")
tokenizer = Tokenizer(inputCol='review', outputCol='tokens')
data = (tokenizer.transform(data)).select("tokens", "sentiment")
remover = StopWordsRemover(inputCol='tokens', outputCol='no_stop_words')
data = remover.transform(data).select('no_stop_words', 'sentiment')
filter_length_udf = udf(lambda row: [x for x in row if len(x) >= 3], ArrayType(StringType()))
data = data.withColumn('words', filter_length_udf("no_stop_words")).select("words", "sentiment")

#Stemming
!pip install nltk
import nltk
from nltk.stem.snowball import SnowballStemmer
stemmer = SnowballStemmer(language='english')
stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))
data = data.withColumn("words_stemmed", stemmer_udf("words")).select('words_stemmed', 'sentiment')

display(data)

#train test split
traindf, testdf = data.randomSplit([0.8, 0.2], seed = 22)
display(traindf)

#calculating prior and word counts in train data
train = traindf.rdd
len_train = train.count()
len_train_pos = train.filter(lambda x: x[1] == "positive").count()
len_train_neg = train.filter(lambda x: x[1] == "negative").count()
prior_pos = len_train_pos/len_train
prior_neg = len_train_neg/len_train
train_pos = train.filter(lambda x: x[1] == "positive").flatMap(lambda x: x[0])
train_neg = train.filter(lambda x: x[1]== "negative").flatMap(lambda x: x[0])
train_pos = train_pos.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x+y).map(lambda x: (x[0], x[1]))
train_neg = train_neg.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x+y).map(lambda x: (x[0], x[1]))
train_vocab = train_pos.fullOuterJoin(train_neg).map(lambda x: (x[0], x[1][0], x[1][1]))
train_vocab = train_vocab.toDF(["word", "c_pos", "c_neg"]).fillna(0)

#laplace smoothing and word probability calculations
v = train_vocab.rdd.count()
count_words = train_vocab.rdd.map(tuple).map(lambda x: (x[1], x[2])).reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]))
train_vocab = train_vocab.rdd.map(lambda x: (x[0], (x[1]+1)/(count_words[0] + v), (x[2]+1)/(count_words[1] + v))).toDF(["word", "p_pos", "p_neg"])

display(train_vocab)

from pyspark.sql.functions import sum as p_sum
import math
test = testdf.rdd
#using log probabilities to avoid underflow
p_not_in_pos = train_vocab.select("p_pos").rdd.flatMap(list).map(lambda x: math.log(1-x)).reduce(lambda x, y: x + y)
p_not_in_neg = train_vocab.select("p_neg").rdd.flatMap(list).map(lambda x: math.log(1-x)).reduce(lambda x, y: x + y)
log_prior_pos = math.log(prior_pos)
log_prior_neg = math.log(prior_neg)
test = test.map(lambda x: ((x[1], x[0]), x[0])).flatMapValues(lambda x: x).map(lambda x: (x[0][0], x[0][1], x[1])).toDF(["y", "data", "word"])
nb = test.join(train_vocab, on = "word", how = "inner").rdd.map(tuple).map(lambda x: (x[0], x[1], x[2], math.log(x[3]/(1-x[3])), math.log(x[4]/(1-x[4])))).toDF(["word", "y", "data", "p_pos", "p_neg"])
nb_rdd = nb.groupBy(["y", "data"]).agg(p_sum("p_pos").alias("pos_prob"), p_sum("p_neg").alias("neg_prob"))
nb_rdd = nb_rdd.select("y", "pos_prob", "neg_prob").rdd.map(tuple).map(lambda x: (x[0], x[1]+p_not_in_pos+log_prior_pos, x[2]+p_not_in_neg+log_prior_neg)).toDF(["y", "pos_prob", "neg_prob"])
nb_rdd_1 = nb_rdd.withColumn("class", nb_rdd.pos_prob - nb_rdd.neg_prob)
nb_rdd_2 = nb_rdd_1.select("y", "class").rdd.map(tuple).map(lambda x: (1.0, x[0]) if x[1]>0 else (0.0, x[0]))
nb_rdd_2 = nb_rdd_2.map(lambda x: (x[0], 1.0) if x[1]=="positive" else (x[0], 0.0))

display(nb_rdd_2)

output = nb_rdd_2.toDF(["prediction", "label"])
display(output)

from pyspark.ml.evaluation import MulticlassClassificationEvaluator
evaluator = MulticlassClassificationEvaluator(predictionCol = "prediction", labelCol = "label", metricName = "accuracy")
accuracy = evaluator.evaluate(output)
print(accuracy)

from pyspark.mllib.evaluation import MulticlassMetrics
metrics = MulticlassMetrics(nb_rdd_2)
print(metrics.confusionMatrix().toArray())
print(metrics.precision(0), metrics.precision(1))
print(metrics.recall(0), metrics.recall(1))

print(prior_pos, prior_neg)